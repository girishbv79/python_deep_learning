{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05aad3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad5d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f082acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66444fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a753cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('labels.csv'),Path('train'),Path('valid')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ef43b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/3'),Path('train/7')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "932d2bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png'),Path('train/3/10093.png'),Path('train/3/10097.png'),Path('train/3/10099.png'),Path('train/3/10116.png'),Path('train/3/10125.png'),Path('train/3/10137.png'),Path('train/3/10141.png'),Path('train/3/10144.png'),Path('train/3/10155.png'),Path('train/3/10161.png')...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training datasets into variables threes and sevens\n",
    "threes = (path/'train'/'3').ls()\n",
    "sevens = (path/'train'/'7').ls()\n",
    "threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fe6a59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 784]), torch.Size([6265, 784]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes = (torch.stack([tensor(Image.open(o)) for o in threes]).float()/255).view(-1, 28*28)\n",
    "stacked_sevens = (torch.stack([tensor(Image.open(o)) for o in sevens]).float()/255).view(-1, 28*28)\n",
    "stacked_threes.shape, stacked_sevens.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f9f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_training_set = torch.cat([stacked_threes, stacked_sevens])\n",
    "# Create a label with 0 for threes and 1 for sevens\n",
    "image_training_labels = tensor([1]*len(stacked_threes) + [0]*len(stacked_sevens))\n",
    "image_training_set.shape, image_training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5da9d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor(1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we need to zip the training set and labels together\n",
    "image_training_data = list(zip(image_training_set, image_training_labels))\n",
    "x,y = image_training_data[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "501f85f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(size, std = 1.0):\n",
    "    return (torch.randn(size) * std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c4e3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_weights((28*28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2923a4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3150], requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = init_weights(1)\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3ccf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myDeepLearningEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
