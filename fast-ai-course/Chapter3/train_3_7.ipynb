{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "05cc4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8496fe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9268, -1.7841,  0.5707,  0.6357],\n",
       "         [ 0.4419, -0.5767, -0.8411, -0.6639],\n",
       "         [-1.0307,  1.3681,  1.1727, -0.0177]]),\n",
       " tensor([[-0.9268, -1.7841,  0.5707,  0.6357,  0.4419, -0.5767, -0.8411, -0.6639, -1.0307,  1.3681,  1.1727, -0.0177]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to view the behavior of view with -1\n",
    "p = torch.randn(3, 4)\n",
    "v = p.view(-1, 12)\n",
    "p, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1cebb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "667f85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (Path/'train'/'3')\n",
    "sevens = (Path/'train'/'7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "acb9a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_threes = torch.stack([tensor(Image.open(o)) for o in threes.ls()]).float()\n",
    "stacked_sevens = torch.stack([tensor(Image.open(o)) for o in sevens.ls()]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9c27b7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes.shape, stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53373a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 1]), torch.Size([12396, 784]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes_and_sevens = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "threes_and_sevens.shape\n",
    "labels_threes_and_sevens = tensor([1]*len(stacked_threes) + [0]*len(stacked_sevens)).unsqueeze(1)\n",
    "labels_threes_and_sevens.shape, threes_and_sevens.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d04c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataLoader and a dataset, dataloader further batches the data for each run\n",
    "dset = list(zip(threes_and_sevens, labels_threes_and_sevens))\n",
    "dl = DataLoader(dset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5a1972e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1]), tensor([-0.0439], requires_grad=True))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights and biases\n",
    "def init_weights(x, b):\n",
    "    w = torch.randn(x).requires_grad_()\n",
    "    bias = torch.randn(b).requires_grad_()\n",
    "    return (w,bias)\n",
    "weights, bias = init_weights(28*28, 1)\n",
    "weights.shape, bias.shape, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "af335534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def model(x, w, bias):\n",
    "    x.shape, w.shape, bias.shape\n",
    "    return x@w + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b5ed545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(preds, labels):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where(labels == 1, 1-preds, preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb2789e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dl, w, b):\n",
    "    for x, y in dl:\n",
    "        preds = model(x, w, b)\n",
    "        print(preds.shape, y.shape)\n",
    "        l = loss(preds, y)\n",
    "        l.backward()\n",
    "        with torch.no_grad():\n",
    "            w -= w.grad * 0.01\n",
    "            b -= b.grad * 0.01\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "        return preds,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5649d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "preds,lo = train_epoch(dl, weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "28e5335e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<fastai.data.load.DataLoader at 0x234740cce90>,\n",
       " 12396,\n",
       " tensor([ 5337.1240,  3769.4934,  1252.2560,    16.8350, -1498.8574, -1158.2384,  2346.7676,  -483.0139,  2418.7122,   882.8147,  6336.2349,  3323.6724,  1973.5610,  6215.3906,   192.1894,  1920.0161,\n",
       "          1099.3776,  3283.0073, -2167.6548,  2999.4233,  3791.1953,  -437.2311,  1540.9291, -3464.7803, -1313.1859, -2253.2002, -1253.3960,  3755.3569, -1911.2413,   459.3077,  3793.5293,  1265.2866,\n",
       "          4401.0176,  3227.8584,  4201.7812,  3844.9172, -1460.2880,   206.8522,   861.3663,  2691.6382,  3167.5559,  1744.1893,  1959.3430,  1493.3798,  3306.4700,  1041.3054,  3790.6538,  3778.6792,\n",
       "          4552.8979,  3248.5388,  1380.2775,  6189.5552,  3949.2300,   849.2740,  3567.3506,  4588.3584,  3618.4272,  1344.4948,  5532.4980,  3192.4297,  1091.0234, -1519.4922,  2045.4062,  5185.5176],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor(0.4609, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl, len(dl.dataset), preds, lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b964b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myDeepLearningEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
